https://medium.com/@dan_abramov/smart-and-dumb-components-7ca2f9a7c7d0

You’ll find your components much easier to reuse and reason about if you divide them into two categories. I call them Container and Presentational components* but I also heard Fat and Skinny, Smart and Dumb, Stateful and Pure, Screens and Components, etc. These all are not exactly the same, but the core idea is similar.


----------------------------
# Smart and Dumb components

smart and dumb components. The smart components are the managers. They follow a few more rules than the controller views, though:

Smart components are in charge of the actions. If a dumb component underneath them needs to trigger an action, the smart component passes a function in via the props. The dumb component can then just treat that as a callback.

Smart components connect a Dumb component to the application architecture, via redux.

### Presentational and Container Components

React bindings for Redux embrace the idea of separating presentational and container components. If you're not familiar with these terms, read about them first, and then come back. They are important, so we'll wait!

Finished reading the article? Let's recount their differences:

	| Presentational Components	| Container Components 	|
	| Purpose	| How things look (markup, styles)	| How things work (data fetching, state updates)	|
	| Aware of Redux	| No	| Yes	|
	| To read data	| Read data from props	| Subscribe to Redux state |
	| To change data	| Invoke callbacks from props	| Dispatch Redux actions	|
	| Are written	| By hand	| Usually generated by React Redux	|


Technically, a container component is just a React component that uses store.subscribe() to read a part of the Redux state tree and supply props to a presentational component it renders. You could write a container component by hand, but we suggest instead generating container components with the React Redux library's connect() function, which provides many useful optimizations to prevent unnecessary re-renders. (One result of this is that you shouldn't have to worry about the React performance suggestion of implementing shouldComponentUpdate yourself.)


-----

Presentational components:
* Are concerned with how things look.
* May contain both presentational and container components** inside, and usually have some DOM markup and styles of their own.
* Often allow containment via this.props.children.
* Have no dependencies on the rest of the app, such as Flux actions or stores.
* Don’t specify how the data is loaded or mutated.
* Receive data and callbacks exclusively via props.
* Rarely have their own state (when they do, it’s UI state rather than data).
* Are written as functional components unless they need state, lifecycle hooks, or performance optimizations.

Examples: Page, Sidebar, Story, UserInfo, List.

My container components:
* Are concerned with how things work.
* May contain both presentational and container components** inside but usually don’t have any DOM markup of their own except for some wrapping divs, and never have any styles.
* Provide the data and behavior to presentational or other container components.
* Call Flux actions and provide these as callbacks to the presentational components.
* Are often stateful, as they tend to serve as data sources.
* Are usually generated using higher order components such as connect() from React Redux, createContainer() from Relay, or Container.create() from Flux Utils, rather than written by hand.
Examples: UserPage, FollowersSidebar, StoryContainer, FollowedUserList.

I put them in different folders to make this distinction clear.

Benefits of This Approach
* Better separation of concerns. You understand your app and your UI better by writing components this way.
* Better reusability. You can use the same presentational component with completely different state sources, and turn those into separate container components that can be further reused.
* Presentational components are essentially your app’s “palette”. You can put them on a single page and let the designer tweak all their variations without touching the app’s logic. You can run screenshot regression tests on that page.
* This forces you to extract “layout components” such as Sidebar, Page, ContextMenu and use this.props.children instead of duplicating the same markup and layout in several container components.
* Remember, components don’t have to emit DOM. They only need to provide composition boundaries between UI concerns.

Take advantage of that.

When to Introduce Containers?

I suggest you to start building your app with just presentational components first. Eventually you’ll realize that you are passing too many props down the intermediate components. When you notice that some components don’t use the props they receive but merely forward them down and you have to rewire all those intermediate components any time the children need more data, it’s a good time to introduce some container components. This way you can get the data and the behavior props to the leaf components without burdening the unrelated components in the middle of the tree.

This is an ongoing process of refactoring so don’t try to get it right the first time. As you experiment with this pattern, you will develop an intuitive sense for when it’s time to extract some containers, just like you know when it’s time to extract a function. My free Redux Egghead series might help you with that too!

Other Dichotomies

It’s important that you understand that the distinction between the presentational components and the containers is not a technical one. Rather, it is a distinction in their purpose.

By contrast, here are a few related (but different!) technical distinctions:
* Stateful and Stateless. Some components use React setState() method and some don’t. While container components tend to be stateful and presentational components tend to be stateless, this is not a hard rule. Presentational components can be stateful, and containers can be stateless too.
* Classes and Functions. Since React 0.14, components can be declared both as classes and as functions. Functional components are simpler to define but they lack certain features currently available only to class components. Some of these restrictions may go away in the future but they exist today. Because functional components are easier to understand, I suggest you to use them unless you need state, lifecycle hooks, or performance optimizations, which are only available to the class components at this time.
* Pure and Impure. People say that a component is pure if it is guaranteed to return the same result given the same props and state. Pure components can be defined both as classes and functions, and can be both stateful and stateless. Another important aspect of pure components is that they don’t rely on deep mutations in props or state, so their rendering performance can be optimized by a shallow comparison in their shouldComponentUpdate() hook. Currently only classes can define shouldComponentUpdate() but that may change in the future.
Both presentational components and containers can fall into either of those buckets. In my experience, presentational components tend to be stateless pure functions, and containers tend to be stateful pure classes. However this is not a rule but an observation, and I’ve seen the exact opposite cases that made sense in specific circumstances.

Don’t take the presentational and container component separation as a dogma. Sometimes it doesn’t matter or it’s hard to draw the line. If you feel unsure about whether a specific component should be presentational or a container, it might be too early to decide. Don’t sweat it!

Example

This gist by Michael Chan pretty much nails it.
https://gist.github.com/chantastic/fc9e3853464dffdb1e3c


Further Reading

* Getting Started with Redux
* Mixins are Dead, Long Live Composition
* Container Components
* Atomic Web Design
* Building the Facebook News Feed with Relay

Footnotes
| * In an earlier version of this article I called them “smart” and “dumb” components but this was overly harsh to the presentational components and, most importantly, didn’t really explain the difference in their purpose. I enjoy the new terms much better, and I hope that you do too!
| ** In an earlier version of this article I claimed that presentational components should only contain other presentational components. I no longer think this is the case. Whether a component is a presentational component or a container is its implementation detail. You should be able to replace a presentational component with a container without modifying any of the call sites. Therefore, both presentational and container components can contain other presentational or container components just fine.


-------

The idea that "React is the V in MVC" is disingenuous. It's a good pitch but, for many of us, it feels like in invitation to repeat our history of coupled views. In practice, React is the V and the C. Dan Abramov describes the division as Smart and Dumb Components. At our office, we call them stateless and container components (view-controllers if we're Flux). The idea is pretty simple: components can't be concerned with both presentation and data-fetching. I feel like an example might be clearer...

A component like this would be rejected in code review for having both a presentation and data concern:

```
// CommentList.js

class CommentList extends React.Component {
  constructor(props) {
    super(props);
    this.state = { comments: [] }
  }

  componentDidMount() {
    $.ajax({
      url: "/my-comments.json",
      dataType: 'json',
      success: function(comments) {
        this.setState({comments: comments});
      }.bind(this)
    });
  }

  render() {
    return <ul> {this.state.comments.map(renderComment)} </ul>;
  }

  renderComment({body, author}) {
    return <li>{body}—{author}</li>;
  }
}
```


It would then be split into two components. The first is like a traditional template, concerned only with presentation, and the second is tasked with fetching data and rendering the related view component.

```
// CommentList.js

class CommentList extends React.Component {
  constructor(props) {
    super(props);
  }

  render() {
    return <ul> {this.props.comments.map(renderComment)} </ul>;
  }

  renderComment({body, author}) {
    return <li>{body}—{author}</li>;
  }
}
// CommentListContainer.js

class CommentListContainer extends React.Component {
  constructor() {
    super();
    this.state = { comments: [] }
  }

  componentDidMount() {
    $.ajax({
      url: "/my-comments.json",
      dataType: 'json',
      success: function(comments) {
        this.setState({comments: comments});
      }.bind(this)
    });
  }

  render() {
    return <CommentList comments={this.state.comments} />;
  }
}
```

In the updated example, CommentListContainer could shed JSX pretty simply.

```
  render() {
    return React.createElement(CommentList, { comments: this.state.comments });
  }
  ```


What does this have to do with disliking JSX?

When we started doing this, concerns about JSX vanished. Writing "dumb components" feels just the same as Handlebars or ERB templates but with the full power of JavaScript. We realized that it wasn't JSX that bothered us as much as the nagging feeling that components were just smaller balls of mud. For a while, our components were just smaller balls of mud but this pattern helped break the cycle.

I hope that this was a helpful addition to the conversation. I've written about it in slightly more detail here. You can also see Jason Bota's talk about how they do this at Facebook.


--------

https://medium.com/@dan_abramov/mixins-are-dead-long-live-higher-order-components-94a0d2f9e750

Mixins Are Dead. Long Live Composition
When React 0.13 came out, everybody freaked out.
The introductory post made it clear that mixins are on their way out:
Unfortunately, we will not launch any mixin support for ES6 classes in React. That would defeat the purpose of only using idiomatic JavaScript concepts.
There is no standard and universal way to define mixins in JavaScript. In fact, several features to support mixins were dropped from ES6 today. There are a lot of libraries with different semantics. We think that there should be one way of defining mixins that you can use for any JavaScript class. React just making another doesn’t help that effort.
One can read this as “mixins will come later” but the truth is that Sebastian Markbåge, the great API terminator, does not favor them:
To be clear, mixins is an escape hatch to work around reusability limitations in the system. It’s not idiomatic React. Making composition easier is a higher priority than making arbitrary mixins work. I’ll focus on making composition easier so we can get rid of mixins.
Why use mixins anyway? What problems do they solve? Can we solve these problems differently, without inheritance, and super woes?
Utility Functions
This case is a no-brainer. If you use mixins to share utility functions, extract them to modules and import and use them directly.
Lifecycle Hooks and State Providers
This is the main use case for mixins. If you’re not very familiar with React’s mixin system, it tries to be smart and “merges” lifecycle hooks. If both the component and the several mixins it uses define the componentDidMount lifecycle hook, React will intelligently merge them so that each method will be called. Similarly, several mixins can contribute to the getInitialState result.
In practice, this behaviour is the single thing that makes mixins useful. They can subscribe the component’s state to a Flux Store or they can work with its DOM node after it is updated. It’s absolutely necessary that any component extension mechanism has the access to the component’s lifecycle.
However mixins are fragile for a number of reasons:
The contract between a component and its mixins is implicit. The mixins often rely on certain methods being defined on the component, but there is no way to see that from the component’s definition.
As you use more mixins in a single component, they begin to clash. For example, if you use something like StoreMixin(SomeStore) and you add another StoreMixin(OtherStore), React will throw an exception because your component now has two versions of methods with the same names. Different mixins will also clash if they define the same state fields.
Mixins tend to add more state to your component whereas you should strive for less. You should read the excellent Why Flux Component is better than Flux Mixin essay by Andrew Clark on this topic.
Mixins complicate performance optimizations. If you define the shouldComponentUpdate method in your components (manually or via PureRenderMixin), you might have issues if some of the mixins need their own shouldComponentUpdate implementations to be taken into account. This can be solved by adding even more “merging” magic, but is it really the way forward?
Enter Higher-Order Components
I first learned about this pattern from a gist by Sebastian Markbåge. The gist is a little bit cryptic if you’re not yet fully comfortable with ES6 syntax, so I’m going to use the “Flux Store mixin” example to explain it.
Note that this is just one possible way of replacing mixins with composition. See the notes at the end of the article for other approaches.
Suppose that you have a mixin that subscribes to the specified Flux Stores and triggers changes in component’s state. It might look like this:
function StoreMixin(...stores) {
  var Mixin = {
    getInitialState() {
      return this.getStateFromStores(this.props);
    },
    componentDidMount() {
      stores.forEach(store =>
        store.addChangeListener(this.handleStoresChanged)
      );
      this.setState(this.getStateFromStores(this.props));
    },
    componentWillUnmount() {
      stores.forEach(store =>
        store.removeChangeListener(this.handleStoresChanged)
      );
    },
    handleStoresChanged() {
      if (this.isMounted()) {
        this.setState(this.getStateFromStores(this.props));
      }
    }
  };
  return Mixin;
}
To use it, the component adds StoreMixin to the mixins list and defines the getStateFromStores(props) function:
var UserProfilePage = React.createClass({
  mixins: [StoreMixin(UserStore)],
  propTypes: {
    userId: PropTypes.number.isRequired
  },
  getStateFromStores(props) {
    return {
      user: UserStore.get(props.userId);
    }
  }
  render() {
    var { user } = this.state;
    return <div>{user ? user.name : 'Loading'}</div>;
  }
How do we solve this without a mixin?
A higher-order component is just a function that takes an existing component and returns another component that wraps it.
Consider this implementation of connectToStores:
function connectToStores(Component, stores, getStateFromStores) {
  const StoreConnection = React.createClass({
    getInitialState() {
      return getStateFromStores(this.props);
    },
    componentDidMount() {
      stores.forEach(store =>
        store.addChangeListener(this.handleStoresChanged)
      );
    },
    componentWillUnmount() {
      stores.forEach(store =>
        store.removeChangeListener(this.handleStoresChanged)
      );
    },
    handleStoresChanged() {
      if (this.isMounted()) {
        this.setState(getStateFromStores(this.props));
      }
    },
    render() {
      return <Component {...this.props} {...this.state} />;
    }
  });
  return StoreConnection;
};
It looks a lot like the mixin, but instead of managing the component’s internal state, it wraps the component and passes some additional props to it. This way wrapper’s lifecycle hooks work without any special merging behavior, by the virtue of simple component nesting!
It is then used like this:
var ProfilePage = React.createClass({
  propTypes: {
    userId: PropTypes.number.isRequired,
    user: PropTypes.object // note that user is now a prop
  },
  render() {
    var { user } = this.props; // get user from props
    return <div>{user ? user.name : 'Loading'}</div>;
  }
});
// Now wrap ProfilePage using a higher-order component:
ProfilePage = connectToStores(ProfilePage, [UserStore], props => ({
  user: UserStore.get(props.userId)
});
That’s it!
The last missing piece is the handling of componentWillReceiveProps. You can find it in the connectToStores source code in the updated Flux React Router Example.
What’s Next
I plan to use higher-order components in the next version of React DnD.
They don’t solve all the use cases for mixins, but come close. Don’t forget that the wrapper can pass arbitrary props to the wrapped component, even the callbacks. It’s possible that the higher-order components can be abused too, but unlike mixins they only rely on simple component composition instead of a bag of tricks and special cases.
There are things you can’t implement with higher-order components. For example, PureRenderMixin would be impossible to implement because the wrapper has no way to look into the wrapper component’s state and define its shouldComponentUpdate. However this is precisely the case where, in React 0.13, you might want to use a different base class, for example PureComponent that descends from Component and implements shouldComponentUpdate. Now that’s a valid use case for inheritance!
Operating on the DOM nodes may also be tricky because the wrapper component has no way to know when the child’s state updates. You can solve this by providing a callback ref (new in React 0.13) as one of the props to the composed component. It can then use ref={this.props.someRef} to notify the higher-order component about attaching and detaching a particular DOM node. The higher-order component can then use React.findDOMNode to work with that node.

Other Approaches
There are other perfectly valid patterns for composition, such as composition right inside render() as used in Flummox. It is also based on nesting, but is less verbose than the higher-order components. This will be even easier in React 0.14, as it switches to parent-based context.
You can always make your own mixin system, if you prefer to. By all means, you’re not limited to the higher order components! I wrote this article to shed more light on this approach. We’ll see what works best over the next months. I’m sure that the winning approaches will rely on composition instead of multiple inheritance (which is what mixins really are).
React is also tackling the problem of sideways data loading through a new API based on Observables. We’ll see what 0.14 brings!


-----

https://medium.com/@learnreact/container-components-c0e67432e005


Container Components

One React pattern that’s had the impact on my code is the container component pattern.

In Jason Bonta talk High Performance Components, there’s this little gem about container components.

The idea is simple:

A container does data fetching and then renders its corresponding sub-component. That’s it.

“Corresponding” meaning a component that shares the same name:

```
StockWidgetContainer => StockWidget
TagCloudContainer => TagCloud
PartyPooperListContainer => PartyPooperList
```

You get the idea.

Why containers?

Say you have a component that displays comments. You didn’t know about container components. So, you put everything in one place:

```
class CommentList extends React.Component {
  this.state = { comments: [] };

  componentDidMount() {
    fetchSomeComments(comments =>
      this.setState({ comments: comments }));
  }
  render() {
    return (
      <ul>
        {this.state.comments.map(c => (
          <li>{c.body}—{c.author}</li>
        ))}
      </ul>
    );
  }
}
```

Your component is responsible for both fetching data and presenting it. There’s nothing “wrong” with this but you miss out on a few benefits of React.

Reusability

CommentList can’t be reused unless under the exact same circumstances.

Data structure

Your markup components should state expectations of the data they require. PropTypes are great for this.
Our component is opinionated about data structure but has no way of expressing those opinions. This component will break silently if the json endpoint change.

Once again. This time with a container

First, lets pull out data-fetching into a container component.

```
class CommentListContainer extends React.Component {
  state = { comments: [] };
  componentDidMount() {
    fetchSomeComments(comments =>
      this.setState({ comments: comments }));
  }
  render() {
    return <CommentList comments={this.state.comments} />;
  }
}
```

Now, let’s rework CommentList to take comments as a prop.

```
const CommentList = props =>
  <ul>
    {props.comments.map(c => (
      <li>{c.body}—{c.author}</li>
    ))}
  </ul>
```

Example Codepen

So, what did we get?
We actually got a lot…
We’ve separated our data-fetching and rendering concerns.
We’ve made our CommentList component reusable.
We’ve given CommentList the ability to set PropTypes and fail loudly.
I’m a big fan of container components. They’re stepping up my React game a lot and making my components easier to read. Give them a try and watch Jason’s talk. It’s excellent!
Carry on, nerds.


------

http://bradfrost.com/blog/post/atomic-web-design/

Atomic Design
Hey there! I wrote a book called Atomic Design that dives into this topic in more detail, which you can buy in paperback and/or ebook formats.

We’re not designing pages, we’re designing systems of components.—Stephen Hay

As the craft of Web design continues to evolve, we’re recognizing the need to develop thoughtful design systems, rather than creating simple collections of web pages.

A lot has been said about creating design systems, and much of it focuses on establishing foundations for color, typography, grids, texture and the like. This type of thinking is certainly important, but I’m slightly less interested in these aspects of design because ultimately they are and will always be subjective. Lately I’ve been more interested in what our interfaces are comprised of and how we can construct design systems in a more methodical way.

In searching for inspiration and parallels, I kept coming back to chemistry. The thought is that all matter (whether solid, liquid, gas, simple, complex, etc) is comprised of atoms. Those atomic units bond together to form molecules, which in turn combine into more complex organisms to ultimately create all matter in our universe.

Similarly, interfaces are made up of smaller components. This means we can break entire interfaces down into fundamental building blocks and work up from there. That’s the basic gist of atomic design.

Periodic Table of the Elements
Josh Duck’s HTML Periodic Table gives a great breakdown of web designers’ atomic elements.
What is Atomic Design
Atomic design is methodology for creating design systems. There are five distinct levels in atomic design:

Atoms
Molecules
Organisms
Templates
Pages
The progression of atomic design: atoms to molecules to organiams to templates to pages

Let’s explore each stage in more detail.

Atoms
Atoms are the basic building blocks of matter. Applied to web interfaces, atoms are our HTML tags, such as a form label, an input or a button.

Atoms

Atoms can also include more abstract elements like color palettes, fonts and even more invisible aspects of an interface like animations.

Like atoms in nature they’re fairly abstract and often not terribly useful on their own. However, they’re good as a reference in the context of a pattern library as you can see all your global styles laid out at a glance.

Molecules
Things start getting more interesting and tangible when we start combining atoms together. Molecules are groups of atoms bonded together and are the smallest fundamental units of a compound. These molecules take on their own properties and serve as the backbone of our design systems.

For example, a form label, input or button aren’t too useful by themselves, but combine them together as a form and now they can actually do something together.

molecule

Building up to molecules from atoms encourages a “do one thing and do it well” mentality. While molecules can be complex, as a rule of thumb they are relatively simple combinations of atoms built for reuse.

Organisms
Molecules give us some building blocks to work with, and we can now combine them together to form organisms. Organisms are groups of molecules joined together to form a relatively complex, distinct section of an interface.

organism

organism-examples

We’re starting to get increasingly concrete. A client might not be terribly interested in the molecules of a design system, but with organisms we can see the final interface beginning to take shape. Dan Mall (who I’m working with on several projects) uses element collages, which articulate ideas for a few key organisms to facilitate client conversations and shape the visual direction (all without having to construct full comps).

Organisms can consist of similar and/or different molecule types. For example, a masthead organism might consist of diverse components like a logo, primary navigation, search form, and list of social media channels. But a “product grid” organism might consist of the same molecule (possibly containing a product image, product title and price) repeated over and over again.

Building up from molecules to organisms encourages creating standalone, portable, reusable components.

Templates
At the template stage, we break our chemistry analogy to get into language that makes more sense to our clients and our final output. Templates consist mostly of groups of organisms stitched together to form pages. It’s here where we start to see the design coming together and start seeing things like layout in action.

template

Templates are very concrete and provide context to all these relatively abstract molecules and organisms. Templates are also where clients start seeing the final design in place. In my experience working with this methodology, templates begin their life as HTML wireframes, but over time increase fidelity to ultimately become the final deliverable. Bearded Studio in Pittsburgh follow a similar process, where designs start grayscale and layout-less but slowly increase fidelity until the final design is in place.

Pages
Pages are specific instances of templates. Here, placeholder content is replaced with real representative content to give an accurate depiction of what a user will ultimately see.

page

Pages are the highest level of fidelity and because they’re the most tangible, it’s typically where most people in the process spend most of their time and what most reviews revolve around.

The page stage is essential as it’s where we test the effectiveness of the design system. Viewing everything in context allows us to loop back to modify our molecules, organisms, and templates to better address the real context of the design.

Pages are also the place to test variations in templates. For example, you might want to articulate what a headline containing 40 characters looks like, but also demonstrate what 340 characters looks like. What does it look like when a user has one item in their shopping cart versus 10 items with a discount code applied? Again, these specific instances influence how we loop back through and construct our system.

Why Atomic Design
In a lot of ways, this is how we’ve been doing things all along, even if we haven’t been consciously thinking about it in this specific way.

Atomic design provides a clear methodology for crafting design systems. Clients and team members are able to better appreciate the concept of design systems by actually seeing the steps laid out in front of them.

Atomic design gives us the ability to traverse from abstract to concrete. Because of this, we can create systems that promote consistency and scalability while simultaneously showing things in their final context. And by assembling rather than deconstructing, we’re crafting a system right out of the gate instead of cherry picking patterns after the fact.

Pattern Lab
In order to apply this methodology in my work, I (along with the help of the great Dave Olsen) created a tool called Pattern Lab to actually create these atomic design systems. I’ll cover Pattern Lab in detail later, but feel free to check it out on Github.

Further Reading
So Andy Clarke has been setting the stage for these types of conversations for a long while now. In fact, he wrote a chapter for Smashing Book 3 called “Becoming Fabulously Flexible: Designing Atoms and Elements.” I had no idea that existed, so how about that! I highly encourage you to check that out. I also highly encourage you to take a look at his tool called Rock Hammer, which is a great way to construct a pattern library utilizing many of these principles.
Web Components: A Tectonic Shift for Web Development – Web Components seem to dovetail really nicely into the concept of atomic design, and watching this video will show why web components
Modularity Tim Berners-Lee discusses how modularity as an important design principle for the Web.
Responsive Deliverables by Dave Rupert talks about the idea of constructing “Tiny Bootstraps, for Every Client”
And here’s the video and slides from my talk on the subject at Beyond Tellerrand in Germany.Brad Frost – Atomic Design – beyond tellerrand 2013 from beyond tellerrand on Vimeo.



I’m really excited to dive in deeper and develop more tools and thoughts around these concepts.

----

https://medium.com/javascript-scene/10-tips-for-better-redux-architecture-69250425af44

10 Tips for Better Redux Architecture

Mandarin Duck — Malcolm Carlaw (CC-BY-2.0)
When I started using React, there was no Redux. There was only the Flux architecture, and about a dozen competing implementations of it.
Now there are two clear winners for data management in React: Redux and MobX, and the latter isn’t even a Flux implementation. Redux has caught on so much that it’s not just being used for React anymore. You can find Redux architecture implementations for other frameworks, including Angular 2. See ngrx:store, for example.
Side note: MobX is cool, and I’d probably choose it over Redux for simple UIs, because it’s less complicated and less verbose. That said, there are some important features of Redux that MobX doesn’t give you, and it’s important to understand what those features are before you decide what’s right for your project.
Side side note: Relay and Falcor are other interesting solutions for state management, but unlike Redux and MobX, they must be backed by GraphQL and Falcor Server, respectively, and all Relay state corresponds to some server-persisted data. AFAIK, neither offers a good story for client-side-only, transient state management. You may be able to enjoy the benefits of both by mixing and matching Relay or Falcor with Redux or MobX, differentiating between client-only state and server-persisted state. Bottom line: There is no clear single winner for state management on the client today. Use the right tool for the job at hand.
Dan Abramov, the creator of Redux made a couple great courses on the topic:
Getting Started with Redux
Building Applications with Idiomatic Redux
Both are great step-by-step tutorials which explain Redux basics, but you’ll also need a higher level understanding to get the most from Redux.
The following are tips that will help you build better Redux apps.
1. Understand the Benefits of Redux
There are a couple important goals for Redux that you need to keep in mind:
Deterministic View Renders
Deterministic State Reproduction
Determinism is important for application testability and diagnosing and fixing bugs. If your application views and state are nondeterministic, it’s impossible to know whether or not the views and state will always be valid. You might even say that nondeterminism is a bug in itself.
But some things are inherently nondeterministic. Things like the timing of user input and network I/O. So how can we ever know if our code really works? Easy: Isolation.
The main purpose of Redux is to isolate state management from I/O side effects such as rendering the view or working with the network. When side-effects are isolated, code becomes much more simple. It’s a lot easier to understand and test your business logic when it’s not all tangled up with network requests and DOM updates.
When your view render is isolated from network I/O and state updates, you can achieve a deterministic view render, meaning: given the same state, the view will always render the same output. It eliminates the possibility of problems such as race conditions from asynchronous stuff randomly wiping out bits of your view, or mutilating bits of your state as your view is in the process of rendering.
When a newbie thinks about creating a view, they might think, “This bit needs the user model, so I’ll launch an async request to fetch that and when that promise resolves, I’ll update the user component with their name. That bit over there requires the to-do items, so we’ll fetch that, and when the promise resolves, we’ll loop over them and draw them to the screen.”
There are a few major problems with this approach:
You never have all the data you need to render the complete view at any given moment. You don’t actually start to fetch data until the component starts to do its thing.
Different fetch tasks can come in at different times, subtly changing the order that things happen in the view render sequence. To truly understand the render sequence, you have to have knowledge of something you can’t predict: the duration of each async request. Pop quiz: In the above scenario, what renders first, the user component or the to-do items? Answer: It’s a race!
Sometimes event listeners will mutate the view state, which might trigger another render, further complicating the sequence.
The key problem with storing your data in the view state and giving async event listeners access to mutate that view state is this:
“Nondeterminism = parallel processing + shared state”
~ Martin Odersky (Scala designer)
Mingling data fetching, data manipulation and view render concerns is a recipe for time-traveling spaghetti.
I know that sounds kinda cool in a B-movie sci-fi kinda way, but believe me, time-traveling spaghetti is the worst tasting kind there is!
What the flux architecture does is enforce a strict separation and sequence, which obeys these rules every time:
First, we get into a known, fixed state…
Then we render the view. Nothing can change the state again for this render loop.
Given the same state, the view will always render the same way.
Event listeners listen for user input and network request handlers. When they get them, actions are dispatched to the store.
When an action is dispatched, the state is updated to a new known state and the sequence repeats. Only dispatched actions can touch the state.
That’s Flux in a nutshell: A one-way data flow architecture for your UI:

Flux Architecture
With the Flux architecture, the view listens for user input, translates those into action objects, which get dispatched to the store. The store updates the application state and notifies the view to render again. Of course, the view is rarely the only source of input and events, but that’s no problem. Additional event listeners dispatch action objects, just like the view:

Importantly, state updates in Flux are transactional. Instead of simply calling an update method on the state, or directly manipulating a value, action objects get dispatched to the store. An action object is a transaction record. You can think of it like a bank transaction — a record of the change to be made. When you make a deposit to your bank, your balance from 5 minutes ago doesn’t get wiped out. Instead, a new balance is appended to the transaction history. Action objects add a transaction history to your application state.
Action objects look like this:

What action objects give you is the ability to keep a running log of all state transactions. That log can be used to reproduce the state in a deterministic way, meaning:
Given the same initial state and the same transactions in the same order, you always get the same state as a result.
This has important implications:
Easy testability
Easy undo/redo
Time travel debugging
Durability — Even if the state gets wiped out, if you have a record of every transaction, you can reproduce it.
Who doesn’t want to have a mastery over space and time? Transactional state gives you time-traveling superpowers:

Redux dev tools history slider view
2. Some Apps Don’t Need Redux
If your UI workflow is simple, all of this may be overkill. If you’re making a tic-tac-toe game, do you really need undo/redo? The games rarely last more than a minute. If the user screws up, you could just reset the game and let them start over.
If:
User workflows are simple
Users don’t collaborate
You don’t need to manage server side events (SSE) or websockets
You fetch data from a single data source per view
It may be that sequence of events in the app is probably sufficiently simple that the benefits of transactional state are not worth the extra effort.
Maybe you don’t need to Fluxify your app. There is a much simpler solution for apps like that. Check out MobX.
However, as the complexity of your app grows, as the complexity of view state management grows, the value of transactional state grows with it, and MobX doesn’t provide transactional state management out of the box.
If:
User workflows are complex
Your app has a large variety of user workflows (consider both regular users and administrators)
Users can collaborate
You’re using web sockets or SSE
You’re loading data from multiple endpoints to build a single view
You could benefit enough from a transactional state model to make it worth the effort. Redux might be a good fit for you.
What do web sockets and SSE have to do with this? As you add more sources of asynchronous I/O, it gets harder to understand what’s going on in the app with indeterminate state management. Deterministic state and a record of state transactions radically simplify apps like this.
In my opinion, most large SaaS products involve at least a few complex UI workflows and should be using transactional state management. Most small utility apps & simple prototypes shouldn’t. Use the right tool for the job.
3. Understand Reducers
Redux = Flux + Functional Programming
Flux prescribes one-way data flow and transactional state with action objects, but doesn’t say anything about how to handle action objects. That’s where Redux comes in.
The primary building block of Redux state management is the reducer function. What’s a reducer function?
In functional programming, the common utility `reduce()` or `fold()` is used to apply a reducer function to each value in a list of values in order to accumulate a single output value. Here’s an example of a summing reducer applied to a JavaScript array with `Array.prototype.reduce()`:

```
const initialState = 0;
const reducer = (state = initialState, data) => state + data;
const total = [0, 1, 2, 3].reduce(reducer);
console.log(total); // 6
```

Instead of operating on arrays, Redux applies reducers to a stream of action objects. Remember, an action object looks like this:

```
{
  type: ADD_TODO,
  payload: 'Learn Redux'
}
```

Let’s turn the summing reducer above into a Redux-style reducer:

```
const defaultState = 0;
const reducer = (state = defaultState, action) => {
  switch (action.type) {
    case 'ADD': return state + action.payload;
    default: return state;
  }
};
```

Now we can apply it to some test actions:

```
const actions = [
  { type: 'ADD', payload: 0 },
  { type: 'ADD', payload: 1 },
  { type: 'ADD', payload: 2 }
];

const total = actions.reduce(reducer, 0); // 3
```

### 4. Reducers Must be Pure Functions

In order to achieve deterministic state reproduction, reducers must be pure functions. No exceptions. A pure function:
Given the same input, always returns the same output.
Has no side-effects.
Importantly in JavaScript, all non-primitive objects are passed into functions as references. In other words, if you pass in an object, and then directly mutate a property on that object, the object changes outside the function as well. That’s a side-effect. You can’t know the full meaning of calling the function without also knowing the full history of the object you passed in. That’s bad.
Reducers should return a new object, instead. You can do that with `Object.assign({}, state, { thingToChange })`, for instance.
Array parameters are also references. You can’t just `.push()` new items to an array in a reducer, because `.push()` is a mutating operation. Likewise, so are `.pop()`, `.shift()`, `.unshift()`, `.reverse()`, `.splice()`, and any other mutator method.
If you want to be safe with arrays, you need to restrict the operations you perform on the state to the safe accessor methods. Instead of `.push()`, use `.concat()`.
Take a look at the `ADD_CHAT` case in this chat reducer:

As you can see, a new object is created with `Object.assign()`, and we append to the array with `.concat()` instead of `.push()`.
Personally, I don’t like to worry about accidentally mutating my state, so lately I’ve been experimenting with using immutable data APIs with Redux. If my state is an immutable object, I don’t even need to look at the code to know that the object isn’t being accidentally mutated. I came to this conclusion after working on a team and discovering bugs from accidental state mutations.
There’s a lot more to pure functions than this. If you’re going to use Redux for production apps, you really need a good grasp of what pure functions are, and other things you need to be mindful of (such as dealing with time, logging, & random numbers). For more on that, see “Master the JavaScript Interview: What is a Pure Function?”.

### 5. Remember: Reducers Must be the Single Source of Truth

All state in your app should have a single source of truth, meaning that the state is stored in a single place, and anywhere else that state is needed should access the state by reference to its single source of truth.
It’s OK to have different sources of truth for different things. For example, the URL could be the single source of truth for the user request path and URL parameters. Maybe your app has a configuration service which is the single source of truth for your API URLs. That’s fine. However…
When you store any state in a Redux store, any access to that state should be made through Redux. Failing to adhere to this principle can result in stale data or the kinds of shared state mutation bugs that Flux and Redux were invented to solve.

In other words, without the single source of truth principle, you potentially lose:

* Deterministic view render
* Deterministic state reproduction
* Easy undo/redo
* Time travel debugging
* Easy testability

Either Redux or don’t Redux your state. If you do it half way, you could undo all of the benefits of Redux.
6. Use Constants for Action Types
I like to make sure that actions are easy to trace to the reducer that employs them when you look at the action history. If all your actions have short, generic names like `CHANGE_MESSAGE`, it becomes harder to understand what’s going on in your app. However, if action types have more descriptive names like `CHAT::CHANGE_MESSAGE`, it’s obviously a lot more clear what’s going on.
Also, if you make a typo and dispatch an undefined action constant, the app will throw an error to alert you of the mistake. If you make a typo with an action type string, the action will fail silently.
Keeping all the action types for a reducer gathered in one place at the top of the file can also help you:
Keep names consistent
Quickly understand the reducer API
See what’s changed in pull requests
7. Use Action Creators to Decouple Action Logic from Dispatch Callers
When I tell people that they can’t generate IDs or grab the current time in a reducer, I get funny looks. If you’re staring at your screen suspiciously right now rest assured: you’re not alone.
So where is a good place to handle impure logic like that without repeating it everywhere you need to use the action? In an action creator.
Action creators have other benefits, as well:
Keep action type constants encapsulated in your reducer file so you don’t have to import them anywhere else.
Make some calculations on inputs prior to dispatching the action.

Reduce boilerplate

Let’s use an action creator to generate the `ADD_CHAT` action object:

```
// Action creators can be impure.
export const addChat = ({
  // cuid is safer than random uuids/v4 GUIDs
  // see usecuid.org
  id = cuid(),
  msg = '',
  user = 'Anonymous',
  timeStamp = Date.now()
} = {}) => ({
  type: ADD_CHAT,
  payload: { id, msg, user, timeStamp }
});
```

As you can see above, we’re using cuid to generate random ids for each chat message, and `Date.now()` to generate the time stamp. Both of those are impure operations which are not safe to run in the reducer — but it’s perfectly OK to run them in action creators.

### Reduce Boilerplate with Action Creators

Some people think that using action creators adds boilerplate to the project. On the contrary, you’re about to see how I use them to greatly reduce the boilerplate in my reducers.

Tip: If you store your constants, reducer, and action creators all in the same file, you’ll reduce boilerplate required when you import them from separate locations.

Imagine we want to add the ability for a chat user to customize their user name and availability status. We could add a couple action type handlers to the reducer like this:

```
const chatReducer = (state = defaultState, action = {}) => {
  const { type, payload } = action;
  switch (type) {
    case ADD_CHAT:
      return Object.assign({}, state, {
        chatLog: state.chatLog.concat(payload)
      });
    case CHANGE_STATUS:
      return Object.assign({}, state, {
        statusMessage: payload
      });
    case CHANGE_USERNAME:
      return Object.assign({}, state, {
        userName: payload
      });
    default: return state;
  }
};
```

For larger reducers, this could grow to a lot of boilerplate. Lots of the reducers I’ve built can get much more complex than that, with lots of redundant code. What if we could collapse all the simple property change actions together?
Turns out, that’s easy:

```
const chatReducer = (state = defaultState, action = {}) => {
  const { type, payload } = action;
  switch (type) {
    case ADD_CHAT:
      return Object.assign({}, state, {
        chatLog: state.chatLog.concat(payload)
      });

    // Catch all simple changes
    case CHANGE_STATUS:
    case CHANGE_USERNAME:
      return Object.assign({}, state, payload);

    default: return state;
  }
};
```

Even with the extra spacing and the extra comment, this version is shorter — and this is only two cases. The savings can really add up.
Isn’t switch…case dangerous? I see a fall through!
You may have read somewhere that `switch` statements should be avoided, specifically so that we can avoid accidental fall through, and because the list of cases can become bloated. You may have heard that you should never use fall through intentionally, because it’s hard to catch accidental fall-through bugs. That’s all good advice, but let’s think carefully about the dangers I mentioned above:

* Reducers are composable, so case bloat is not a problem. If your list of cases gets too large, break off pieces and move them into separate reducers.
Every case body returns, so accidental fall through should never happen. None of the grouped fall through cases should have bodies other than the one performing the catch.
* Redux uses `switch..case` well. I’m officially changing my advice on the matter. As long as you follow the simple rules above (keep switches small and focused, and return from every case with its own body), `switch` statements are fine.

You may have noticed that this version requires a different payload. This is where your action creators come in:

```
export const changeStatus = (statusMessage = 'Online') => ({
  type: CHANGE_STATUS,
  payload: { statusMessage }
});

export const changeUserName = (userName = 'Anonymous') => ({
  type: CHANGE_USERNAME,
  payload: { userName }
});
```

As you can see, these action creators are making the translation between the arguments, and the state shape. But that’s not all they’re doing…

### 8. Use ES6 Parameter Defaults for Signature Documentation

If you’re using Tern.js with an editor plugin (available for popular editors like Sublime Text and Atom), it’s going to read those ES6 default assignments and infer the required interface of your action creators, so when you’re calling them, you can get intellisense and autocomplete. This takes cognitive load off developers, because they won’t have to remember the required payload type or check the source code when they forget.
If you’re not using a type inference plugin such as Tern, TypeScript, or Flow, you should be.
Note: I prefer to rely on inference provided by default assignments visible in the function signature as opposed to type annotations, because:
You don’t have to use a Flow or TypeScript to make it work: Instead you use standard JavaScript.
If you are using TypeScript or Flow, annotations are redundant with default assignments, because both TypeScript and Flow infer the type from the default assignment.
I find it a lot more readable when there’s less syntax noise.
You get default settings, which means, even if you’re not stopping the CI build on type errors (you’d be surprised, lots of projects don’t), you’ll never have an accidental `undefined` parameter lurking in your code.

### 9. Use Selectors for Calculated State and Decoupling

Imagine you’re building the most complex chat app in the history of chat apps. You’ve written 500k lines of code, and THEN the product team throws a new feature requirement at you that’s going to force you to change the data structure of your state.
No need to panic. You were smart enough to decouple the rest of the app from the shape of your state with selectors. Bullet: dodged.

For almost every reducer I write, I create a selector that simply exports all the variables I need to construct the view. Let’s see what that might look like for our simple chat reducer:

```
export const getViewState = state => Object.assign({}, state);
```

Yeah, I know. That’s so simple it’s not even worth a gist. You might be thinking I’m crazy now, but remember that bullet we dodged before? What if we wanted to add some calculated state, like a full list of all the users who’ve chatted during this session? Let’s call it `recentlyActiveUsers`.
This information is already stored in our current state — but not in a way that’s easy to grab. Let’s go ahead and grab it in `getViewState()`:

```
export const getViewState = state => Object.assign({}, state, {
  // return a list of users active during this session
  recentlyActiveUsers: [...new Set(state.chatLog.map(chat => chat.user))]
});
```

If you put all your calculated state in selectors, you:
Reduce the complexity of your reducers & components
Decouple the rest of your app from your state shape
Obey the single source of truth principle, even within your reducer

### 10. Use TDD: Write Tests First

Many studies have compared test-first to test-after methodologies, and to no tests at all. The results are clear and dramatic: Most of the studies show between 40–80% reduction in shipping bugs as a result of writing tests before you implement features.
TDD can effectively cut your shipping bug density in half, and there’s plenty of evidence to back up that claim.
While writing the examples in this article, I started all of them with unit tests.
To avoid fragile tests, I created the following factories that I used to produce expectations:

```
const createChat = ({
  id = 0,
  msg = '',
  user = 'Anonymous',
  timeStamp = 1472322852680
} = {}) => ({
  id, msg, user, timeStamp
});

const createState = ({
  userName = 'Anonymous',
  chatLog = [],
  statusMessage = 'Online',
  currentChat = createChat()
} = {}) => ({
  userName, chatLog, statusMessage, currentChat
});
```

Notice these both provide default values, which means I can override properties individually to create only the data I’m interested in for any particular test.
Here’s how I used them:

```
describe('chatReducer()', ({ test }) => {
  test('with no arguments', ({ same, end }) => {
    const msg = 'should return correct default state';

    const actual = reducer();
    const expected = createState();

    same(actual, expected, msg);
    end();
  });
});
```

Note: I use tape for unit tests because of its simplicity. I also have 2–3 years’ experience with Mocha and Jasmine, and miscellaneous experience with lots of other frameworks. You should be able to adapt these principles to whatever framework you choose.
Note the style I’ve developed to describe nested tests. Probably due to my background using Jasmine and Mocha, I like to start by describing the component I’m testing in an outer block, and then in inner blocks, describe what I’m passing to the component. Inside, I make simple equivalence assertions which you can do with your testing library’s `deepEqual()` or `toEqual()` functions.
As you can see, I use isolated test state and factory functions instead of utilities like `beforeEach()` and `afterEach()`, which I avoid because they can encourage inexperienced developers to employ shared state in the test suite (that’s bad).
As you’ve probably guessed, I have three different kinds of tests for each reducer:
Direct reducer tests, which you’ve just seen an example of. These essentially test that the reducer produces the expected default state.
Action creator tests, which test each action creator by applying the reducer to the action using some predetermined state as a starting point.
Selector tests, which tests the selectors to ensure that all expected properties are there, including computed properties with expected values.
You’ve already seen a reducer test. Let’s look at some other examples.


Action Creator Tests

```
describe('addChat()', ({ test }) => {
  test('with no arguments', ({ same, end}) => {
    const msg = 'should add default chat message';

    const actual = pipe(
      () => reducer(undefined, addChat()),
      // make sure the id and timestamp are there,
      // but we don't care about the values
      state => {
        const chat = state.chatLog[0];
        chat.id = !!chat.id;
        chat.timeStamp = !!chat.timeStamp;
        return state;
      }
    )();

    const expected = Object.assign(createState(), {
      chatLog: [{
        id: true,
        user: 'Anonymous',
        msg: '',
        timeStamp: true
      }]
    });

    same(actual, expected, msg);
    end();
  });


  test('with all arguments', ({ same, end}) => {
    const msg = 'should add correct chat message';

    const actual = reducer(undefined, addChat({
      id: 1,
      user: '@JS_Cheerleader',
      msg: 'Yay!',
      timeStamp: 1472322852682
    }));
    const expected = Object.assign(createState(), {
      chatLog: [{
        id: 1,
        user: '@JS_Cheerleader',
        msg: 'Yay!',
        timeStamp: 1472322852682
      }]
    });

    same(actual, expected, msg);
    end();
  });
});
```

This example is interesting for a couple of reasons. The `addChat()` action creator is not pure. That means that unless you pass in value overrides, you can’t make a specific expectation for all the properties produced. To deal with this, we used a pipe, which I sometimes use to avoid creating extra variables that I don’t really need. I used it to ignore the generated values. We still make sure they exist, but we don’t care what the values are. Note that I’m not even checking the type. We’re trusting type inference and default values to take care of that.
A pipe is a functional utility that lets you shuttle some input value through a series of functions which each take the output of the previous function and transform it in some way. I use lodash pipe from `lodash/fp/pipe`, which is an alias for `lodash/flow`. Interestingly, `pipe()` itself can be created with a reducer function:

```
const pipe = (...fns) => x => fns.reduce((v, f) => f(v), x);

const fn1 = s => s.toLowerCase();
const fn2 = s => s.split('').reverse().join('');
const fn3 = s => s + '!'

const newFunc = pipe(fn1, fn2, fn3);
const result = newFunc('Time'); // emit!
```

I tend to use `pipe()` a lot in the reducer files as well to simplify state transitions. All state transitions are ultimately data flows moving from one data representation to the next. That’s what `pipe()` is good at.
Note that the action creator lets us override all the default values, too, so we can pass specific ids and time stamps and test for specific values.

Selector Tests

Lastly, we test the state selectors and make sure that computed values are correct and that everything is as it should be:

```
describe('getViewState', ({ test }) => {
  test('with chats', ({ same, end }) => {
    const msg = 'should return the state needed to render';
    const chats = [
      createChat({
        id: 2,
        user: 'Bender',
        msg: 'Does Barry Manilow know you raid his wardrobe?',
        timeStamp: 451671300000
      }),
      createChat({
        id: 2,
        user: 'Andrew',
        msg: `Hey let's watch the mouth, huh?`,
        timeStamp: 451671480000 }),
      createChat({
        id: 1,
        user: 'Brian',
        msg: `We accept the fact that we had to sacrifice a whole Saturday in
              detention for whatever it was that we did wrong.`,
        timeStamp: 451692000000
      })
    ];

    const state = chats.map(addChat).reduce(reducer, reducer());

    const actual = getViewState(state);
    const expected = Object.assign(createState(), {
      chatLog: chats,
      recentlyActiveUsers: ['Bender', 'Andrew', 'Brian']
    });

    same(actual, expected, msg);
    end();
  });
});
```

Notice that in this test, we’ve used `Array.prototype.reduce()` to reduce over a few example `addChat()` actions. One of the great things about Redux reducers is that they’re just regular reducer functions, which means you can do anything with them that you’d do with any other reducer function.
Our `expected` value checks that all our chat objects are in the log, and that the recently active users are listed correctly.
Not much else to say about that.

Redux Rules

If you use Redux correctly, you’re going to get major benefits:
* Eliminate timing dependency bugs
* Enable deterministic view renders
* Enable deterministic state reproduction
* Enable easy undo/redo features
* Simplify debugging
* Become a time traveler

But for any of that to work, you have to remember some rules:
* Reducers must be pure functions
* Reducers must be the single source of truth for their state
* Reducer state should always be serializable
* Reducer state should not contain functions

Also keep in mind:
* Some Apps don’t need Redux
* Use constants for action types
* Use action creators to decouple action logic from dispatch callers
* Use ES6 parameter defaults for self-describing signatures
* Use selectors for calculated state and decoupling

Always use TDD!

---------------------------------------------

Use DumbComponents to render *everything*.
Don’t even put a <div> in a SmartComponent. It should only ever be composing DumbComponents for you. Separate your concerns — and don’t start just doing “one little thing here”!

Use SmartComponents to generate actions creators.
When a DumbComponent has an interaction from a user, it shouldn’t handle any logic itself — it should blindly call a function which is passed to it by a SmartContainer and let it do the work.
The SmartContainer should then marshal the necessary data and pass it to an action creator.


-----

Rule: Smart components are not allowed to have any logic except dispatching actions.
Rule: Smart components should always access state through selectors.
Rule: Minimize view logic in smart components by extracting it into dumb components.

Summary of our opinionated workflow rules
* App state is a first class citizen, structure it like an in-memory database.
* Smart components are not allowed to have any logic except dispatching actions.
* Smart components should always access state through selectors.
* Minimize view logic in smart components by extracting it into dumb components.
* Place all business logic inside action handlers (thunks), selectors and reducers.
* Services must be completely stateless.


-----------------

https://medium.freecodecamp.com/scaling-your-redux-app-with-ducks-6115955638be

Although not in the scope of this article, I want to touch this single idea: always separate State Management files from UI files.
Think about your application on the long run. Imagine what happens with the codebase when you switch from React to another library. Or think how your codebase would use ReactNative in parallel with the web version.
Our approach starts from the need to isolate the React code into a single folder — called views — and the redux code into a separate folder — called redux.

This first level split gives us the flexibility to organize the two separate parts of the app completely different.
Inside the views folder, we prefer a function-first approach in structuring files. This feels very natural in the context of React: pages, layouts, components, enhancers etc.


duck
-- actions.js
-- index.js
-- operation.js
-- reducers.js
-- selectors.js
-- tests.js
-- types.js
-- utils.js

Types
The types file contains the names of the actions that you are dispatching in your application. As a good practice, you should try to scope the names based on the feature they belong to. This helps when debugging more complex applications.

```
const QUACK = "app/duck/QUACK";
const SWIM = "app/duck/SWIM";

export default {
    QUACK,
    SWIM
};
```

Actions

This file contains all the action creator functions.

```
import types from "./types";

const quack = ( ) => ( {
    type: types.QUACK
} );

const swim = ( distance ) => ( {
    type: types.SWIM,
    payload: {
        distance
    }
} );

export default {
    swim,
    quack
};
```

Notice how all the actions are represented by functions, even if they are not parametrized. A consistent approach is more than needed in a large codebase.

Operations

To represent chained operations you need a redux middleware to enhance the dispatch function. Some popular examples are: redux-thunk, redux-saga or redux-observable.
In our case, we use redux-thunk. We want to separate the thunks from the action creators, even with the cost of writing extra code. So we define an operation as a wrapper over actions.
If the operation only dispatches a single action — doesn’t actually use redux-thunk — we forward the action creator function. If the operation uses a thunk, it can dispatch many actions and chain them with promises.

```
import actions from "./actions";

// This is a link to an action defined in actions.js.
const simpleQuack = actions.quack;

// This is a thunk which dispatches multiple actions from actions.js
const complexQuack = ( distance ) => ( dispatch ) => {
    dispatch( actions.quack( ) ).then( ( ) => {
        dispatch( actions.swim( distance ) );
        dispatch( /* any action */ );
    } );
}

export default {
    simpleQuack,
    complexQuack
};
```

Call them operations, thunks, sagas, epics, it’s your choice. Just find a naming convention and stick with it.

At the end, when we discuss the index, we’ll see that the operations are part of the public interface of the duck. Actions are encapsulated, operations are exposed.

Reducers

If a feature has more facets, you should definitely use multiple reducers to handle different parts of the state shape. Additionally, don’t be afraid to use combineReducers as much as needed. This gives you a lot of flexibility when working with a complex state shape.

```
import { combineReducers } from "redux";
import types from "./types";

/* State Shape
{
    quacking: bool,
    distance: number
}
*/

const quackReducer = ( state = false, action ) => {
    switch( action.type ) {
        case types.QUACK: return true;
        /* ... */
        default: return state;
    }
}

const distanceReducer = ( state = 0, action ) => {
    switch( action.type ) {
        case types.SWIM: return state + action.payload.distance;
        /* ... */
        default: return state;
    }
}

const reducer = combineReducers( {
    quacking: quackReducer,
    distance: distanceReducer
} );

export default reducer;
```

In a large scale application, your state tree will be at least 3 level deep. Reducer functions should be as small as possible and handle only simple data constructs. The combineReducers utility function is all you need to build a flexible and maintainable state shape.

Check out the complete example project and look how combineReducers is used. Once in the reducers.js files and then in the store.js file, where we put together the entire state tree.

Selectors

Together with the operations, the selectors are part of the public interface of a duck. The split between operations and selectors resembles the CQRS pattern.
Selector functions take a slice of the application state and return some data based on that. They never introduce any changes to the application state.

```
function checkIfDuckIsInRange( duck ) {
    return duck.distance > 1000;
}

export default {
    checkIfDuckIsInRange
};
```

Index

This file specifies what gets exported from the duck folder. It will:
* export as default the reducer function of the duck.
* export as named exports the selectors and the operations.
* export the types if they are needed in other ducks.

```
import reducer from "./reducers";

export { default as duckSelectors } from "./selectors";
export { default as duckOperations } from "./operations";
export { default as duckTypes } from "./types";

export default reducer;
```

Tests

A benefit of using Redux and the ducks structure is that you can write your tests next to the code you are testing.

Testing your Redux code is fairly straight-forward:

```
import expect from "expect.js";
import reducer from "./reducers";
import actions from "./actions";

describe( "duck reducer", function( ) {
    describe( "quack", function( ) {
        const quack = actions.quack( );
        const initialState = false;

        const result = reducer( initialState, quack );

        it( "should quack", function( ) {
            expect( result ).to.be( true ) ;
        } );
    } );
} );
```

Inside this file you can write tests for reducers, operations, selectors, etc.
I could write a whole different article about the benefits of testing your code, there are so many of them. Just do it!

------

https://medium.com/@rajaraodv/the-anatomy-of-a-react-redux-app-759282368c5a

6 Types Of Components

Now, if you inspect using React Developer Tools, you’ll realize that in a typical multi-view SPA React Redux app, we can categorize components into at least 6 different types based on their “purpose”.

* “Provider” component ➡ Injects “Store” to sub components
* “Router” & “RouterContext” component ➡ Navigation
* “Parent” Route component ➡ Main App-level wrapper component
* “Page” or “View” Route sub-component ➡ Helps organize stuff inside a single page or view.
* “Container” components ➡ Deals w/ Redux And “Presentational”
* “Presentational” components ➡Renders the HTML and Listens to Events

----

https://medium.com/horrible-hacks/things-i-wish-i-knew-about-redux-9924abf2f9e0

Its okay to connect many components. Redux used to recommend only connecting a few components (and putting them in a containers folder). Now they don’t. Thank goodness. Stuffing all your data into a handful of connected components sucked. Passing a bunch of props over and over sucked even more. There are places where containers make sense. But you shouldn’t feel pressured to structuring all of your code into a few connected containers.
